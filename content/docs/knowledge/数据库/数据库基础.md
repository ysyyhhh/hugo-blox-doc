
# 数据库

## 索引

### **B树与B+树的结构**

B树是**多关键字平衡树**,且节点内的关键字是有序的.每个节点都存储其关键字指向的具体数据地址.

B+树是在B树的基础上, 非叶子节点仅指向其多个子节点的地址 , 只有叶子节点指向具体以堆文件形式存放的数据块地址. 相邻叶子节点也通过指针连接. 方便快速范围查询.

不同之处:

- 层数更低: 相比于B树, B+树的非叶子节点全部用于索引,使得B+树的层数更低,
- 效率稳定, B+树一定只能在叶子节点找到数据的具体地址, 每次查询的路径长度基本一致.
- 范围查询: B+树的叶子节点有next指针, 使得范围查询效率更高.

### **为什么不用其他数据结构做索引，而用B树或B+树**

- 链表, 链表的查询速度是O（N），每次查询都得从链表头开始查询，例如上面查询“xiaxia”，如果xiaxia在1000的位置，那么需要遍历1000次才能查找到。
- 数组:查询速度O（1），但删除插入是O(n), 且数据必须存在于内存, 索引过大时无法存储.
- 平衡二叉树
  - 二叉查找树查询的时间复杂度是O（logN），查找速度最快和比较次数最少. 但在树形结构下,影响查询效率的因素主要是树的深度, B树的深度远比平衡二叉树小。

### **B树索引的适用范围**:

- 全键值匹配
- 匹配最左前缀
  匹配列前缀
- 匹配范围值
  精确匹配某一列并范围匹配另外一列
  只访问索引的查询

### **什么时候使用B树索引 / B树的索引可用性**:

1、只需要获取少量的行;(确保使用索引比不使用索引更高效)

2、即便获取很多行，但是可以只使用索引不使用基本表。(索引中包含整个表)

### **索引有哪些？索引分类**

#### 按照物理存储分类

聚簇索引
  - 按照数据存放的**物理位置为顺序**的索引结构，聚集索引的**叶子节点包含了整个数据行**。
  - InnoDB表要**求必须有聚簇索引，默认在主键字段上建立聚簇索引**
  - 每个表**只能有一个聚集索引**，它对应的索引键值也是表的**主键或唯一约束条件**。
  - 通过聚集索引，我们可以快速地按照主键或唯一约束条件查询和排序表中的数据, **提高多行检索速度**
 
非聚簇索引
  - 索引顺序与数据**物理列排序无关**，**叶节点仍然是索引节点(指向主键)**
  - 每个表可以有**多个非聚集索引**，这些索引可以覆盖**多个数据列**，以满足不同的查询需求。
  - 通过非聚集索引，快速地**定位表中符合查询条件的记录的主键**，然后进行(回表查询)。

#### 按字段特性

**单列索引**：对**单列创建索引**，**叶子节点包含索引列的值**，并且**根据单列排序**。

**联合索引**：同时对**多列创建索引**，**叶子节点会同时包含每个索引列的值**，并且同时**根据多列排序**，这个排序和我们所理解的字典序类似。


**覆盖索引**: 如果**非聚簇符合索引**已经能够得到**查询的所有信息**了，就**无需再回表**，即只按照条件**找主键**。

#### 按数据结构分类
B+索引

**哈希索引**

所有的数据类型，通过哈希函数变成一个**等长的哈希值**。

将这个**等长的哈希值**作为**组织成索引的结构 —— 哈希链表**。

哈希链表的结点上，**储存哈希值** 和 **指向记录哈希值的地址 uid（索引行的地址）**。



**哈希索引能做什么不能做什么？**

- 哈希索引只能用来进行**全键值**的查询
  - 不能前缀查询
- 哈希索引只支持**击中运算符**
  - 击中运算符：= , != , in
- 哈希索引**不支持范围查询**
- 哈希索引**不支持对字段排序**(因为只支持击中运算符)
- 哈希索引**读取效率高于B树索引**
  - 哈希索引结构非常**紧凑**.
  - 哈希索引**使用数值的比较**,远**高于字符串比较**速度.

**函数索引**

B树索引是对一个字段构建索引,而函数索引是对**这个字段上的一个函数值**构建索引.

**结构同样是B+树索引,只是节点的关键字是函数的值而不是字段值.**

是最具创造力的索引结构,用得好可用解决并发冲突,优化存储结构.等很多事情.

**能用在哪**

- **不区分大小写**查询

- **T、F比例巨大差异**的查询

- **有选择的唯一性**

  - 项目表有两个状态, active和inactive.

    要求active的项目,必须要有唯一名. 而inactive没有这个要求.

    解决方法: **函数索引上构建唯一索引**.

**位图索引**

用一个**索引键条目（01图）存储指向多行**的指针。

**位图索引适合**

- **相异基数(distinct cardinality)低**的字段进行快速查询 (复合查询)
  - 可以取的值的范围小: 性别、真假,年龄段 等.
  - 使用B树索引,需要复合索引时 组合数多. 且共同的值多, 可能使得叶子结点远少于索引结点.
  - 使用哈希索引,碰撞率贼高.
- 大量**临时查询的聚合**

**位图索引对于写操作非常不友好**/位图索引**不能应用在OLTP**应用中的原因



**原因**: 位图索引的**键值指向多行**, 如果一个session修改了一个索引的数据,则**该索引指向的所有行都会被查找到**.无法锁定单独一个条目,**可能在修改时要锁住整个目录**,导致并发性下降严重 几乎变成串行化. 


**位图连结索引**

- 允许使用**另外某个表的列** 对 **一个给定表** 建立索引。
- 实际上，这就是允许**对一个索引结构**(而不是表本身)中的数据进行**逆规范化**。

位图联结索引的**前提条件**:

**必须连接到另一张表的主键/唯一键**

**反向键索引或叫避向索引“eseindex)**

1. 将键值反向插入，以免并发插入时都插入到同一个块。
2. 此时进程将竞争同一个索引页,插入并发性大幅度下降

### **索引的5种优点**

- 可以大大加快数据的**检索**速度
- 可以加速表和表之间的**连接**，特别是在实现数据的参照完整性方面特别有意义
- 在使用分组和排序子句进行数据检索式，同样可以显著减少查询中**分组和排序**的时间
- 通过创建**唯一性**索引，可以保证数据库表中每一行数据的唯一性
- 通过使用索引，可以在查询的过程中，使用**优化隐藏器**，提高系统的性能

### **系统对外键建立索引很普遍。为什么要对外键建立索引？**

- 加快对于父表和子表的**连接查询**.
- **删除操作**时，可以快速通过外键的索引找到**主表中**要删除的行。
- **避免死锁**, 有外键时会导致两个表都要上锁.
  - 添加索引能够让**上锁后操作的时间变短**, .并发时需要 A表加锁/B表加锁。 

### **不加索引的外键情况**

- **子表不容易**修改
  - 不从子表中删除记录
  - 是一个字典表,不容易被修改.
- 一般**不进行父表和子表的连接查询**

### **建立索引的条件 / 请解释数据库管理员如何为数据库建立一组好的索引**

- **经常搜索**的列
- 经常**使用where子句**的列上，加快条件的判断速度
- 经常进行**范围搜索**的列上，因为索引已经排序了，其指定的范围是连续的.
- **唯一性**的列:在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构
- 经常**需要排序**的列上，因为索引已经排序了，查询可以利用索引的排序，加速排序查询时间.
- **经常用在连接的列**，这些列**主要是外键**，可以加快连接速度
- **数据分布较广的列**:

### **哪些列上不应该加索引**

- **很少使用**或者参考的列不应该创建索引。
- **很少的数据值**列不应该创建索引。
- **text,image,bit数据类型**的列不应该加索引。
  - 比较和排序的开销大.
  - 因为这些列要么数据量很大，要么很小，不利于使用索引
- **修改需求大**的列.

### **为什么数据库管理员一般不会给所有单个属性都建立索引，请写出两条原因**

- 过多的索引会**加重优化器**查找最优查询计划的负担
- 会增加数据库**维护索引的负担**.
- 一旦聚集索引改变，**所有非聚集索引都会跟着改变**
- 该列是**属于不该建立索引**的列时.

### **为什么没有使用我的索引**

- **使用B+树索引**，但**没有使用索引的最前列**
- **不能为NULL建立索引条目**
  - **COUNT(*)**， 包括NULL, t会引起**全表扫描**，
  - is not NULL
- **函数查询**时不使用索引
- **隐形函数查询**，比如**<>不等于符**，会**引起全表扫描**
- **隐式类型转换**，如字符串转成数值来比较
- 如果用了我的索引，实际反而会更慢。
  - 即查询**优化器发现有比使用你的索引更快的访问方式**
- **没有正确的统计信息**，造成CBO无法做出正确的选择
- 两个条件用 **or 连接**，一个有索引一个没索引

总结成两条：

- “不能使用索引，使用索引会返回不正确的结果”
- “不该使用索引，如果使用了索引就会变得更慢”

### 如何查看索引是否被使用

- **explain**命令
  - `explain select * from company_info where cname like '%小%'` 
  - 看possible_keys和key列

### **索引带来的问题（负面的）,使用索引会降低查询效率的情况**：

- 总是**存在索引不被使用**的情况。
  - 存在索引时, 创建索引会带来系统的维护和空间的开销.
  - 因此索引如果不被使用反而会降低效率. 
- 当**一次查询的结果集较大**时，索引会影响效率。
  - 因为**索引是针对点查询**的，而不是针对某个范围查询的。此时有可能不使用索引反而效率更高.
  - 一般结果集在10%以下可以考虑使用索引。
- 对于**修改需求大的表**中，使用索引会严重影响数据库更新操作的效率。
- 太多索引会让**设计不稳定**

### **设计索引时需要考虑的主要因素**

- 在**适合加**索引的列上加索引
- 不在**不应该加**索引的列上加索引
- 不要加**过多**的索引
- 确保建立该索引后**能够被使用**
- 确保索引带来的**好处大于索引带来的问题**



### **聚簇索引 -clustered index 或者 -clustering index**

为了使得**表中数据有序**,  很多数据库使用了**聚簇索引**.

聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，这个叶子节点也被称为数据页。每张表只能拥有一个聚簇索引。

- **范围查询效率非常高**
- 代价: **非范围查询也要进行范围扫描**

- **主键更新会导致记录的重新排序，从而导致记录物理位置的变化**

- 为了更加安全, 聚簇索引可以和索引组织表一样，根据主键来定义. 因为主键被更新的概率小,或者说不应该被更新.

- 聚簇索引**也可以是非主键索引,这是和索引组织表不一样的地方**.

聚簇索引和IOT的区别在于索引键的选择和存储方式。

- 聚簇索引只包括表的主键，并将表的数据按照主键值的顺序存储在硬盘上；
- IOT包括表的主键和数据列，并将数据和索引存储在同一个结构中。


## 事务

### **为什么要加锁**

- 多个应用程序**同时对相同数据进行访问**。
- **保证数据库的完整性和一致性**，就必须要有一定的机制用于控制数据记录的读取、插入、删除和更新。
- 通过对数据库对象加锁，我们可以**避免由于并发更改造成数据的丢失**

### **加锁与提交**

- 想要使加锁时间最短，必须**频繁的提交**
- 但如果每个逻辑单元完成后都提交**会增加大量开销**
- 对于批处理程序，并发控制不是问题，**避免频繁提交才是明智的做法**。
- 对于用户交互程序，则需要**高频提交，加快释放锁**。

### **加锁与可伸缩性**

- 与表级锁相比，行级锁能产生更佳的**吞吐量**
- **行级锁大都性能曲线很快达到极限**

### **加锁处理的原则**

- **不要随便使用表级锁**
- 尽量**缩短加锁时间**
- **索引也需要维护**
- 编程上的原则(语句性能高，未必程序性能高（下面有4点）)
  - 避免SQL语句上的**循环处理**
  - 减少程序和数据库之间的**交互次数**
  - 充分利用DBMS提供的机制，使**跨机器交互的次数**降至最少
  - 把所有**不重复不必要的SQL语句放在逻辑工作单元**之外


### 锁的分类

悲观锁：

- 指在读写数据时，认为**数据很可能会被其他并发操作所修改**.
  - 因此在**进行操作之前，先加锁，**确保数据不会被其他操作修改。
- 悲观锁适用于并发写操作多，**读操作少**的场景
  - 例如**银行转账等涉及到账户余额变动**的场景。
- 悲观锁的缺点是在**并发量高时，会导致大量的阻塞和等待**。

乐观锁：

- 指在读写数据时，认为**数据不会被其他并发操作所修改.**
  - 因此在进行操作之前，不加锁，但在**提交数据时，检查数据是否被其他操作所修改，如果没有修改，则提交成功，否则返回错误信息**。
- 乐观锁适用于并发读操作多，**写操作少**的场景.
  - 例如商品库存等只需要查询不需要修改的场景。
- 乐观锁的优点是可以**大大降低阻塞和等待**，但是需要在提交数据时进行额外的校验，**增加了程序开发和维护的难度**。

共享锁（Shared Lock）：

- **允许多个事务进行读操作，但不允许写操作**。
- 共享锁适用于多个事务**只读同一份数据**的场景。
- 适用于读多写少的场景，例如在线图书馆、新闻网站等需要大量读取数据的应用，可以使用共享锁来**提高并发读取的能力，避免写操作的阻塞**。

排他锁（Exclusive Lock）：

- **只允许一个事务进行写操作**，其他事务**不能进行读写操作**。
- 适用于写多读少的场景，
- 例如银行转账、在线购物等需要对数据进行修改的应用，可以使用排他锁来保证操作的原子性，**避免读写冲突和数据不一致性**。

行级锁（Row Lock）：

- 针对数据表中的某一行数据进行加锁，**只有在访问该行数据时才会加锁**，这样可以**提高并发性能**。
- 例如社交网络、在线游戏等需要**频繁更新数据,高并发**的应用，可以使用行级锁来控制并发更新，提高系统的并发能力和性能。

间隙锁（Gap Lock）：

- 针对数据表中**不存在的数据进行加锁**，可以防止其他事务在这个间隙中插入数据。
- 适用于对数据表中不存在的数据进行加锁的场景，例如对于需要**进行范围查询或者范围删除的应用**，可以使用间隙锁来避免其他事务在查询或删除操作中插入数据，保证数据的一致性和正确性。(避免幻读)

意向锁（Intention Lock）：

- 在加行级锁和表级锁**之前，先进行意向锁的判断**，以**提高加锁效率**。
- 例如在多个事务同时请求对同一数据行进行更新时，可以使用意向锁来提前判断需要加的锁类型，**避免不必要的锁竞争和死锁问题**。

### **必须由程序员利用程序语言控制并发更新的情况:**

- 业务规则**复杂的更新**：如果更新操作需要依赖多个表或者多个条件，并且需要保证操作的原子性，就需要使用事务来控制并发更新。
- **分布式系统中的数据更新**：在分布式系统中，不同节点之间可能会同时更新同一份数据，如果不加控制，就会导致数据的不一致性。因此，在分布式系统中，需要使用分布式锁来控制并发更新。
- **批量数据更新**：如果需要批量更新数据，而且更新的数据量很大，可能会导致数据库锁表或者死锁等问题。因此，需要**将批量更新操作分批进行**，或者**使用分布式锁**来控制并发更新。
- **大量并发更新**：如果并发更新的请求数量非常大，可能会导致数据库性能下降或者崩溃。因此，**需要使用连接池、缓存等技术来优化数据库性能，或者使用分布式锁来分散并发更新的压力。**

### **资源竞争解决方案有哪些**

- DBA解决方案：针对事务空间、可用列表
  - 增加分配给储物条目的空间缓解冲突
  - 让**insert分配到不同的物理块**.

- 架构解决方案：分区、逆序索引、索引组织表

- 开发解决方案：
  - 调节**并发数**
    - 限制session个数为最高性能的session个数，使周转更快
  - **不使用系统产生值**
    - 连续值只在范围查询中使用，在连续值本身毫无现实意义的情况下，范围查询的场景也不多见;
    - 可以只使用随机数来做主键，遇到随机数碰撞，就再生成一个随机数.

总结：**与加锁不同，数据库竞争是可以改善的**。架构师、开发者和DBA都可以从各自的角度改善竞争


### **并发操作主要解决哪三个问题**

- **丢失修改**：T1和T2读入同一数据并修改，T2提交的结果破坏了T1的提交，导致T1修改被丢失
- **读脏数据**：T1修改某一数据并将其写回磁盘，T2读取同一数据后，T1由于某种原因被撤销，数据也做了恢复，此时T2读的数据和数据库里的数据不一致，T2读到脏数据，即不正确数据
- **不可重复读**：T1读数据后，T2对其修改，T1无法再现前一次读取结果



### 事务的隔离级别

未提交读（Read Uncommitted）：事务可以读取未提交的数据，也称作脏读（Dirty Read）。一般很少使用。

提交读（Read Committed）：是大都是 DBMS （如：Oracle, SQLServer）默认事务隔离。执行两次同意的查询却有不同的结果，也叫不可重复读。

可重复读（Repeable Read）：是 MySQL 默认事务隔离级别。能确保同一事务多次读取同一数据的结果是一致的。可以解决脏读的问题，但理论上无法解决幻读（Phantom Read）的问题。


可串行化（Serializable）：是最高的隔离级别。强制事务串行执行，会在读取的每一行数据上加锁，这样虽然能避免幻读的问题，但也可能导致大量的超时和锁争用的问题。很少会应用到这种级别，只有在非常需要确保数据的一致性且可以接受没有并发的应用场景下才会考虑。

MySql实现的哪种隔离级别
- 可重复读

实现方式: MVCC

### MVCC原理

- **多版本并发控制**，是一种并发控制方法，用于实现事务隔离级别。
- 通过保存数据在某个时间点的快照来实现事务的隔离。

- 当前事务内的更新，可以读到；
- 版本未提交，不能读到；
- 版本已提交，但是却在快照创建后提交的，不能读到；
- 版本已提交，且是在快照创建前提交的，可以读到；


### 事务隔离级别的实现

- **未提交读**：不加锁
- **提交读**：加行级锁
- **可重复读**：
  - MySQL的InnoDB存储引擎通过**多版本并发控制（MVCC）**来实现可重复读。
- **可串行化**：加表级锁

### **事务的ACID特性**

- **原子性（Atomicity）**：事务是一个不可分割的工作单位，事务中的操作要么都做，要么都不做。
- **一致性（Consistency）**：事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。
- **隔离性（Isolation）**：一个事务的执行不能被其他事务干扰。
- **持久性（Durability）**：事务一旦提交，它对数据库中的数据的改变就是永久性的。

## SQL优化

### **Sql中使用绑定变量的优点与缺点**

**绑定变量实质就是变量**。类似于我们是用过的替代变量（占位符）。就是在sql语句中使用变量，通过改变变量的值来得到不同的结果。

sql语句是分为动态部分和静态部分的。而动态部分在一般的情况下，对执行计划的影响是微乎其微的。

**同一个sql语句有不同动态部分生成的执行计划是相同的。**

优点：

- 使用动态绑定，可以**减少sql的解析**，从而减少了数据库引擎在sql解析上资源的消耗。
- 提高了**执行效率和可靠性**。减少对数据库的访问实际上就是减少了数据库的工作量

缺点：

- 可能长时间使用动态sql，由于参数的不同。可能sql的**执行效率不同**；
- **使用不当会有安全问题 sql注入**

### **实现数据安全性控制的常用方法和技术**

数据库管理系统提供的安全措施主要包括

- 用户**身份鉴别**
- 自主存取控制 Discretionary Access Control 
- 强制存取控制 Mandatory Access Control
- **视图**机制
- **审计**
- 数据**加密**存储和加密传输等

### **登记日志的原则（运行记录优先原则）是什么，为什么** 

**运行记录优先原则**:

1. **登记的次序严格按并发事务执行的时间次序**
2. 必须**先写日志文件，后写数据库**

如果先写了数据库修改，而在运行记录中没有登记下这个修改，则以后就**无法恢复这个修改**了。

如果先写日志，但没有修改数据库，按日志文件恢复时只不过是多执行一次**不必要的UNDO操作**，并**不会影响数据库的正确性**。

所以为了安全，一定要先写日志文件，即首先把日志记录写到日志文件中，然后写数据库的修改。这就是**“先写日志文件”的原则**

### SQL 语句的执行过程，并简单对各个步骤的所花费的代价大小进行描述和比较。

1. 语法分析：确保语句的正确性和有效性。代价很小，语法分析器已预先定义了所有合法的 SQL 语法。
2. 语义分析：需要检查语句中的**对象是否存在**、**用户是否有访问权限**等信息。代价比语法分析高一些。
3. 解析（软解析和硬解析）：将 SQL 语句转换成执行计划，比语义分析高。需要进行语法转换、查询优化等复杂操作。
   1. 在软解析过程中，DBMS 会查找已经编译好的执行计划缓存，如果找到了对应的执行计划就直接使用.
   2. 否则会进行硬解析，生成新的执行计划，此时代价最大。
   3. 执行计划生成：生成最优的执行计划，以最小化查询的代价。代价最高，需要进行大量的计算和查询优化。
4. 查询执行：按照执行计划执行查询，并从磁盘中读取数据、对数据进行排序、过滤和聚合等操作，可能还需要进行大量的磁盘和内存交换。代价取决于查询本身的复杂度以及所涉及的数据量。

综合来看，SQL 语句的执行过程中，查询优化和查询执行往往是代价最大的两个步骤。在实际应用中，可以通过**优化查询语句的结构**、**创建合适的索引**、**优化查询计划**等手段来提高查询性能，从而减少查询优化和查询执行所需的代价。



### **SQL 优化原理是什么？优化的逻辑是怎样的？对此经验之谈**

SQL 优化的原理：

- 通过**优化查询的执行计划**
- **减少查询的时间和资源消耗**
- 提高数据库系统的**性能**。

SQL 优化的逻辑一般可以分为以下几个步骤：

1. 优化**查询语句**：对查询语句进行优化，包括**重写查询语句**、**使用索引**、**避免全表扫描**等。
2. 优化**数据库结构**：根据业务需求优化数据库中表的**结构、索引、分区**等，以提高查询和更新操作的性能。
3. 优化**硬件环境**：优化数据库所在的硬件环境，包括 CPU、内存、磁盘、网络等，以提高数据库系统的整体性能。

对于 SQL 优化的经验之谈，以下是一些常见的建议：

1. 将**过滤条件进行排序**,好的过滤条件先做
2. 使用**join来暗示表连接顺序**，当有多表连接操作时，考虑使用**exists和in操作来优化**
3. **避免过度连接表**，将多维度的查询进行降维处理，一次连接的表不要超过3张，超过就将非关联子查询变成内嵌视图。
   - 聚合子查询转化为JOIN
   - 非关联子查询变成内嵌视图
4. **避免在高层使用distinct**，用exists和in来处理
5. **避免在高层使用select ***, 这样会产生**冗余的结果集，降低性能**
6. **不要滥用子查询**. 子查询有如下好处,除这些好处外,不要用
   1. 分辨过滤条件的好坏
   2. 避免顶层的distinct

总之，SQL 优化需要根据具体的情况进行分析和优化，需要综合考虑查询的复杂度、数据的规模和类型、硬件环境等因素。

### **SQL有什么优化策略，从硬件、系统、应用上分析**

这个优化法则归纳为5个层次：

- 减少数据访问（**减少磁盘访问**）系统上
  - 正确使用**索引**
  - **优化执行计划**
  - 尽量使用**自带函数**,慎用自定义函数.
- 减少服务器CPU开销（**减少CPU**及内存开销）
  - 使用**绑定变量**
  - 合理使用**排序**
  - 减少**模糊查找**
- 返回**更少数据**（减少网络传输或磁盘访问）应用上
  - 数据**分页**处理
  - 返回**只需要的字段**
- 减少交互次数（减少网络传输）应用上
  - 一次连接批量处理数据
  - 使用存储过程.
- 利用更多资源（硬件上）
  - 扩大内存
  - 增加CPU
  - 更快的硬盘
  - 更高速的网络



### **请描述Oracle中IOT的物理存储结构和读取数据的方式，并与堆文件的物理存储结构和读取数据的方式进行比较后解释IOT的适用范围。**

IOT（**Index-Organized** Table）索引组织表 是一种基于B+树的索引类型，它的索引键包括表的主键和数据列。IOT的数据访问和索引访问是一体化的。

IOT通常用于**需要频繁地使用主键查询**的表，因为IOT将主键值和对应的数据行存储在同一个B+树节点中，可以减少磁盘I/O操作的次数，从而提高查询性能。

与堆文件的存储结构相比。

- 堆文件的存储是**随机存储**的，而IOT使用的B树结构是**根据主键按照一定顺序存储**的。
- 堆文件的读取是需要**遍历整个堆文件数据**的，而IOT则可以**通过主键的信息**快速定位到相关节点，读取数据。

IOT适用范围：

- **主键很少更新**。因为主键更新会导致B树结构的重新调整。
- **多用主键查询**。因为IOT是以主键为节点构造B树的，以主键信息查询能较快找到对应节点。
- **很少插入新数据**。插入新数据会导致B树重新调整。
- 希望数据已某种特定的**顺序物理存储**，那也适合用IOT

**IOT的优点**

- **记录排序**，查询效率贼强
- **节约磁盘空间开销**，主键没有空间开销，索引就是数据


**IOT缺点**

- **插入效率也许低于堆文件**

- 对于**经常更新的表不适合用IOT**，因为维护的索引代价大，更何况是多字段索引

## 分库分表

分库 就是将数据库中的数据分散到不同的数据库上，可以垂直分库，也可以水平分库。
分表 就是将数据库中的数据分散到不同的表上，可以垂直分表，也可以水平分表。

### 分区的作用与类型

**分区的作用**: 提高**并发性和并行性**，从而增强系统架构的**可伸缩性**

**分区的类型**（不一定是方式）

循环分区：**不受数据影响**的内部机制。分区定义为各个磁盘的存储区域；可以看作是随意散布数据的机制；保持更改带来的磁盘I/O操作的平衡 

数据驱动分区：根据**一个或多个字段中的值(分区键)**来定义分区。是一种手工分区，一般叫分区视图.

### **数据驱动分区的实现方式**

**哈希分区(Hash-partitioning)**

- 对**分区键进行哈希运算**，根据运算结果进行分区.
- 能保证**根据分区键可以快速找到记录**，但对范围搜索没有任何帮助。
- 其实更接近与循环分区, 只是它还能**负载均衡提高并发**的能力. 

**范围分区(Range- partitioning)**

- 滑动窗口，就是范围分区，**根据连续数据的范围**对数据进行分区。
- **非常适合处理历史数据**，每一个分区专门用来存储**特定范围内的数据**。
- 一般系统还会设定**else分区**,来存储所有**可能漏网的数据**(其他)
- 应用: 时间范围, 字母范围

**列表分区(List-partitioning)**

- 是一种最具手工风格的分区类型，适合**定制某种特殊的解决方案**。
- **分区键必须明确指定**，但**分区键只能有一列**，不能像范围或者哈希分区那样同时指定多个列做为分区键，但它的**单个分区对应值可以是多个**。

- 一旦插入的列值不在分区范围内，则插入/更新就会失败.
- 因此
  通常建议使用列表分区时，要创建一个**default分区**存储那些**不在指定列表内的记录**。

**复合分区**:

- 很多数据库中分区可以嵌套，即分区可以再建立子分区，叫sub partition.子分区是分区内的分区。

- 一种二位分区处理的方法，比如在时间的分区中，建立哈希分区,范围-哈希分区、范围-列表分区等
- **OB把它叫做二级分区**，再举个例子，**类似于用户账单领域，会按照user id做哈希分区，按照账单创建时间做范围分区**。

数据驱动的分区是最常使用的分区方式，用数据值本身作为分区的基础，这时候**数据分区最具有开发使用的价值**。

### **分区是如何提高查询效率**

分区后，逻辑上表仍然是一张完整的表，只是将表中的数据在物理上存放到多个表空间（物理文件上），利于高速检索，**查询数据时，不至于每次都扫描整张表**.

### **分区的优点和缺点**

**优点**：

- 增强**可用性**：如果表的某个分区出现故障，表在其他分区的数据仍然可用；
- **维护**方便：如果表的某个分区出现故障，需要修复数据，只修复该分区即可；
- **均衡I/O**：可以把不同的分区映射到磁盘以平衡I/O，改善整个系统性能；
- 改善**查询性能**：对分区对象的查询可以仅搜索自己关心的分区，提高检索速度。

**缺点**：

- 除了堆文件之外的任何存储方法，都会**带来复杂性**
- **选错存储方式**会带来大幅度的性能降低
- 降低了并发个数，但如果**涉及数据量非常庞大**，**降低并发所带来的缺陷远远小于分区所带来的性能提高**
- 由于**强制的部分数据聚合**可能会**导致其他数据的分散**，所以不同的查询请求也可能会形成性能上的矛盾

### **数据分区的最佳方法**

- 当**数据分区键均匀分布时**，分区表查询收益最大
- **避免更新分区键**, 更新分区键会影响数据移动
- **不在更新数据频繁时使用分区**.
- **考虑整体**,当有多个处理执行时，解决方案就不应该过度偏袒其中任何一个


## 模型

### **面向对象中可持久化类的父类子类继承关系，如何映射到关系数据库中，有哪几种情况, 每种情况下的表结构设计是怎姓的。(层次结构)**

例子:

指挥官和士兵

每人都有唯一的ID, 名字(name), 描述(description)



**邻接模型**

- 层次中**父记录ID**作为子记录(childrow) 的一个属性。

- 设计直观简单,但会导致**递归的查询**。

**原理**：

- **在邻接表中**，所有的数据均拥有一个Parent字段，用来存储它的父节点。
- 当前节点为根节点的话，它的父节点则为NULL。
- 在遍历的时候，可以使用递归来实现查询整棵树，从根节点开始，不断寻找子节点（父节点->子节点->父节点->子节点）

**优点：**

- **快速获取直接父子节点**，很容易**插入新节点**。
- 容易实现
  - 使用Connect by容易实现
  - 递归实现，用oracle的with，表示出树的层次
- 三种树状模型中**性能最高**，每秒返回的查询记录最多；只需要遍历一次，**但不是基于关系的处理**，性能最好

**缺点：**

- 为了避免多次交互,**每次获得整张表**
  - 比如查询后代节点树，需要用到递归，要发送多次的请求，与数据库交互多次。
  - 一般**为了避免递归给数据库发送sql**，采用**一次性读取整个表**的数据，然后在应用端构建树的方法。
- **查询子树性能不好**
  - 只需要某一个子树，仍然要把整个树加载出来，性能上并不好；
- **删除中间节点**
  - 要删除中间层结点时，需要同时删除该节点下的所有节点，否则会出现孤立节点；

**举例**:

表结构定义 : model(**id**,parent_id,description,commander)

**自顶向下SQL**:

```sqlite
select level,* from model
connect by parent_id = prior.id
start with commander = "Root Commander"
```

不用connect by时，需要使用with as来递归

```sql
//定义起点
select level,* from model where commader = "Root Commander"

//定义递归体
select parant.level + 1,child.id,child.description,child.commander
from query parent,model child where child.parent_id = parent.id


with recursive_query(level,id,description,commander) as (
    select 1 as level,* from model where commader = "Root Commander"
    union all
    select parant.level + 1,child.id,child.description,child.commander
from recursive_query parent,model child where child.parent_id = parent.id
)

//但这是层次遍历
select level,* from recursive_query;
```

**自底向上SQL**:

```sql
select level,* from model
connect by id = prior.parent_id
start with description like "%Highland%"
无法看到树,因为无法存储中间结果集
```

**物化路径模型**

每一个节点都存储节点的**完整路径**，一般用字符串存，它允许节点之间有顺序.

每个节点保存的结构信息里包括

- 祖先各节点的路径
- 后代节点路径的一部分
- 兄弟节点路径的长度
- 节点所在层次等等。

1代表第一章;

1.2代表第一章第二节;
1.2.3代表第一章第二节
第三小节。

**优点：**

- **性能良好**，借助了unix文件目录的思想，主要是**以空间换时间**；
- **可靠性**（**容易实现**，不容易出bug）
- **可维护性**（简单、不需要依赖大量额外的处理逻辑）
- 并且通过**比较路径字符串长度**也容易知道树的深浅

**缺点：** 

- **不能实现无限深度的树**，每个节点的子节点数有上限；
- 而且深度越大，路径越长，还要解决操作过程中**节点路径的唯一性**；
- 树的深度要自己**写函数计算**
- **物化路径不应该是KEY**，即使他们有唯一性，因为主键最好不更新原则。
- 数据库**无法确保路径格式正确**，只能**由应用程序来验证**
- 查询**复杂度主要在路径字符串的处理**

**与邻接模型的差别**:

- 邻接模型的**子节点是平等**的,且可以**无限扩展**。
- 物化路径模型可以指出**兄弟的排名**。

**影响物化路径模型的因素**

- 计算**深度**
  计算两个**字符串函数的差**，所带来的代价;
- **缩排**函数
  物化路径模型需**不断地处理字符串**，在where子句中不断的执行字符串操作，处理速度比邻接模型更慢。

**表结构定义** : model(**path**,description,commander)

**自顶向下查询**:

自定义函数

```sql
create
        function m_depth(path varchar)
        returns int        
begin
        return length(path) - length(replace(path,'.',''))
end;
```



```sql
select lpad(a.description,length(a.description) + mp_depth(a.path)) description,a.commander
from 
model a,model b
where a.path like b.path || '%'
and b.commander = "Root Commander"
order by a.path
```





**自底向上查询**:

```sql
select lpad(a.description,length(a.description) + mp_depth(b.path) - mp_depth(a.path)) description,a.commander,a.path
from 
model a,model b
where b.path like a.path || '%'
and b.decription like "%Highland%"
order by a.path desc
```



嵌套集合模型

- 每一个节点都有一个左编号(left_num)和右编号(right_num)，包含其所有的子节点的左右数字.

- 确定这二个值的方法是对树进行一次深度优先遍历，在逐层深入的过程中依次递增地分配left_num的值，并在返回时依次递增地分配right_num的值

- 数据元素之间不再是点和线的关系，而是以**容纳和被容纳**的方式

**优点：** 

- **易理解**
- **查找某一个节点的子节点很容易**，
- 删除一个非叶子节点时，它的**后代会自动替代被删除的节点**，成为其直接祖先节点的直接后代；

**缺点：**

- 但是对**结果集排序不好操作**，缩排无法处理
- 数据**更新、插入、删除**开销大
- **计算量大，对存储程序要求高**

**影响嵌套集合模型性能的因素**:

- **找后代方面胜于其他两个模型**，但为**缩排付出更大代价**
- **额外的连接**，以及group by所做的**深度**有关
- **改善嵌套集合模型性能代价巨大,但引入冗余**

**应用场景：**

如果**简单快速的查询是最重要的功能**，那么可以使用嵌套集合。

然而，在嵌套集中**插入和移动节点是复杂**的，因为需要**重新分配左右值**，因此嵌套集不适合需要频繁插入和删除节点的应用场景

**表结构定义**:  model(<u>left_num</u>,<u>right_num</u>,commander,description)

**自顶向下查询**:

找后代直接,找范围就可以. 排序不可以

```sql
select * from model a,model b
where b.commander = "Root Commander" and a.left_num between b.left_num and b.right_num
```

找level,需要再加一个 a b中间加一个c

```sql
select lpad(description,length(description + depth))from
(select count(a.left_num) depth, a.description,a.commander ,a.left_num from model a,model b,model c
where b.commander = "Root Commander" 
and c.left_num between b.left_num and b.right_num
and a.left_num between c.left_num and c.right_num
group by a.description,a.commander,a.left_num)
order by left_num

```

**自底向上查询**:

```sql
b是a的父亲,通过b找包括自己的所有父亲数量来定义深度.

select lpad(description, length(description) + 6 - depth,  commander
from (select distinct b.description,
      b.commander,
      b.left_num,
      (select count(c.left_num) 
       from model c 
       where b.left_num between c.left_num and c.right_num) depth 
      
      from a, model b 
      where a.description like '%Highland%' 
      and a.left_num between b.left_num and b.right_num 
      and b.left_num > 1) 
order by left_num desc;
```

- 动态计算深度依旧是个问题·
- 不要显示人造根节点
- 硬编码最大深度 (为了缩排显示)



**嵌套间隔模型(nested interval)**

思想是以两个数字为特定节点的**路径编码**，这两个数字被解释成有理数(就是分数)的**分子和分母**。  太复杂了不讲.

多父节点模型?

**闭包表模型：**闭包表是一个简单、优雅模型，它记录了树中所有节点的关系，将树中任何具有祖先与后代关系的节点对，都存储在 TreePaths 中，同时我们也把指向节点自身的关系也存储在这张表；为了方便查询某个节点直接父节点或直接子节点，我们还增加一个 path_length 字段，自我引用的节点该值为 0，直接子节点为 1

**优点：**它需要一张额外的表来存储关系，是一种典型的采用空间来换时间的方案，查询、插入、删除都比较简单

**缺点**：占用太多空间；

**三种层次模型的查询效率比较**

自顶向下查询：Vandamme查询

效率：邻接模型>物化模型>嵌套集合模型

- 邻接模型
  - 利用了**递归**
  - 内部connect by是用**过程化方法**实现的，**未利用关系模型实现**。
  - 是进行**字符比较**，并且置于内存中进行计算，比较快速; 
- 物化路径
  - 利用**关系模型进行表联接**，通过字符串前缀比较确定是否是父子关系。
  - 效率低下的主要原因是**字符串操作，比如字符串拆分**（物化路径如果解决了用**字符型代替字符串型表示目录时，效率会大大提高**）
- 嵌套模型
  - **虽然找出子节点很容易**，
  - 但确定子节点的**深度**，对子节点**排序**以及缩排比较**复杂**

自底向上访问：Highland查询

- 邻接表模型
- 不管是自底向上的查询还是自顶向下查询，效率都是一样的。
- 物化路径
  - 因为**自底向上需要遍历很多节点**，而**自顶向下只需要遍历一个节点**，自底向上查询远远低于自定上下查询
- 嵌套集合模型
  - 自顶向下查询与自底向上查询效率**差不多**
  - 但多了排序过程，**排序比较耗时**

效率：邻接模型>物化模型>嵌套集合模型

**物化路径模型**是**最通用的最均衡**的树状结构设计方案

**自底向上查询慢于自顶向下查询的原因**:

- 自顶向下查询只有一个起点;,**自底向上查询可能有多个出发点**。
  ·多个记录都包含highland查询。
- **不能使用索引**,导致完整地表扫描

### 反范式与打破范式要考虑的因素

**反范式**: 引入**受控的冗余**，通过放松规范化规则来**提高系统的性能,降低数据模型的复杂度**. 通常包括将多个表合并成一个表，增加冗余数据，以及创建复合索引等技术手段。

**打破范式需要考虑的三因素**

- 规范弱化使得**实现变得更加复杂**，因为需要**手动保持数据的完整性**。

- 规范弱化会**降低灵活性**。
- 规范弱化会加快元组检索的速度，但却会**使更新速度变慢**。

### **判断是否应该使用逆范式的条件/什么时候可以不遵守范式**：

- 数据**表非常大**或**查询非常频繁**，导致查询性能严重下降；
  - 大型电商网站, 订单读取非常频繁,把订单和订单详细信息合并提高效率
- **存在大量连接操作**，导致查询复杂度极高；
  - 社交媒体软件,用户的关系复杂. 经常需要使用用户的关系信息.把关系信息合并到用户信息中.
- 需要**快速读取大量数据**，而**不需要强制保证数据的实时性**；
- **修改频率非常低**，数据更新的代价相对较小。
  - 博客网站,文章和评论都很多时,只需要最新的数据,且不容易修改.
  - 可以把新的播客信息和评论合并成一个表.





### **打破范式的步骤**:

1. 画好ER模型
2. 分辨一对一、一对多和多对多关系
3. 构建三范式表结构设计。
4. 考虑打破范式



### **七大反范式Pattern**

**Pattern 1** **合并一对一关系**

合并：基于全部参与的实体为主，引入部分参与的表。

- 会产生大量空值

- 若两边都部分参与则不能合并

如，将“员工”和“员工地址”表合并为一个表，其中包含员工和他们的地址信息。

**Pattern 2** **一对N的关系复制非键值减少连接**

适用条件：两表连接时最主要的事务都与某非键值相关

- 最需要关注更新，可能需要**使用触发器**。

如：查询学生信息以及学生所在学院

例如，在“订单”和“订单行项目”表之间的一对多关系中，将订单头信息（如客户名称、订单日期等）复制到订单行项目表中。

**Pattern 3** **在一对N关系中复制外键来减少JOIN表数量**

为减少或删除常用或关键查询的连接，复制关系中一个或多个外键列来提高
查询的效率。

例如，在“订单”和“订单行项目”表之间的一对多关系中，将订单表的外键（如客户id）复制到订单行项目表中。

**Pattern 4** **多对多关系中复制属性来减少JOIN表数量**

把两张表中经常需要的属性都拷贝到同一关系表中

在“学生”和“课程”之间的多对多关系中，将学生和课程的属性（如姓名、课程名称等）复制到“选课”关联表中

**Pattern 5** **引入重复组**

通常对于一个多值属性，值不太多（小于等于10），且不会经常变，可以在表中见多个有关属性列

如一个人有地址一、地址二、地址三

 将学生的多个地址存储在一个单一字段中，并将其标记为重复组。

**Pattern 6** **建立提取表**

将查询慢的表需要连接成大表并储存下来。

查询可以访问派生数据并在同一组基表上执行多表联接。

不能做实时计算，得到数据可能是**相对静态**
的，也可能不一定是最新的。

好处大，缺点非常大

带来非常大的复杂性，导致数据库中存在各种同步的、异步的、有用的没用的提取表。
数据更新耗费后续人员极长时间.

**Pattern 7** **分区**

将大型表分割为更小的逻辑部分，以便更好地管理和查询数据。

例如，将“销售记录”表分成按日期、地理区域或销售代表等逻辑分区。



### **范式的价值或者作用**

1NF 每个属性不可再分， 确保**原子性**，具有原子性的价值

2NF 主键可以唯一标识记录. 非主属性完全依赖候选键.检查对键的完全依赖，价值在于**控制数据冗余和查询性能**

3NF 消除对主属性的传递依赖,非主键属性之间不能相互依赖，检查**属性的独立性**

BCNF: 每一个函数依赖的决定因素都包含候选键

四范式:消除多值依赖.

所以范式的价值在于：

- 降低**冗余**
- 消除**操作异常**
- 合理规范化的模式**可应对需求变更**；


## 数据库类型

### **列数据库是什么**

**列数据库**是将传统的表格形式拆分为单列存储，**存储方式**是列数据库与传统数据库的最大差别。这个差别同时**带给了列数据库高效的查询性能**。

即每一列的数据的存储在一个连续空间的,且有序,因此只要找到了主键在第几个位置,就可以快速找到其他属性的元素.

### **Redis、memcache、mongoDb特点和区别**

**Redis**

内存型KV数据库，适合**读多写少**的业务场景。很适合做缓存。 

优点：

- 支持**多种数据类型** string、list、set、zset、hash
- **读写性能优异**。
- 数据可以**持久化**保持（AOF、快照），写入硬盘，
- 支持**灾难恢复，主从复制**。主机会自动将数据同步到从机，可以进行读写分离。

 缺点：

- redis较**难支持在线扩容**，当集群数据达到上限在线扩容变得复杂。
- **主从宕机** 会导致前端读写失败，主从数据复制过程中，数据未完全复制到从机，会出现数据不一致。

应用场景：

- 在程序和关系型数据库**中间做高速缓存**
- 缓存**高频数据,降低IO次数**
- 分布式架构中做**session共享**

例子：

- 比如微信token每两小时刷新一次，就比较适合用redis存储，读也比较方便；
- 在线游戏排行榜；计时达到一定时间后显示相关广告；按照用户投票和时间排序，更新新闻；
- 统计在某段特点时间里有多少特定用户访问了某个特定资源，统计哪些特定用户访问了某篇的文章；

**Memcache**

高性能的**分布式内存对象缓存**系统，基于一个**存储键/值对**的hashmap

优点, 基于其**分布式特性**

- **均衡请求**
- 增加**缓存容量**
- **部分容灾**:多台MC服务器使用哈希一致性算法,当有一台挂掉时,能保留部分请求.

缺点

- 只支持**简单的key/value数据**结构，不像Redis可以支持丰富的数据类型。
- **无法进行持久化**，数据不能备份，只能用于缓存使用，且重启后数据全部丢失。

 应用场景：

- **分布式缓存**
- 数据库前段缓存
- 服务器间数据共享

**MongoDB**

是**文档型**的非关系型数据库，使用**json结构**。

优点

- **查询功能**强大：json文档结构的存储方式，能够更便捷的获取数据
- 能存储**海量数据**
- **海量数据下性能优越**

缺点

- 占用**内存过大** 。
- **不支持事务**。
- 模式自由,自由灵活的文件存储**格式带来的数据错误**
- MongoDB没有成熟的**维护工具**。

应用场景:

- 存放**评论等半结构化数据**
- 适合**存储json**类型数据
- **不经常变化**,朋友圈,日志,直播礼物

**应用场景**

redis: 数据量较**小的更性能操作和运算**上。

memcache: 用于在**动态系统中减少数据库负载**，提升性能;做缓存，提高性能（适合读多写少，对于数据量比较大，可以采用sharding）。

MongoDB:主要解决**海量数据的访问效率**问题。

### **数据仓库**

主要功能是 将OLTP经年累月所累积的大量数据，通过**数据仓库特有的数据储存架构进行 OLAP**，最终帮助决策者能快速有效地从大量数据中，分析出有价值的信息，提供决策支持. **仍然是结构化数据**

与数据库的区别: 数据库面向的是OLTP.，数据仓库面向OLAP

数据仓库是一个用以更好地支持企业决策分析处理的、面向主题的、集成的、不可更新的、随时间不断变化的数据集合

- **面向主题**：主题是个抽象的概念，是**在较高层次上将企业信息系统中的数据综合、归类并进行分析利用**的抽象，比如对于商场而言，主题就包括供应商、商品、顾客等
- **集成**的：数据仓库的数据是**从原有分散的数据库数据中抽取的**，因此数据在进入前必然经过加工与集成，同一与综合
- **不可更新**的：所涉及的数据操作主要是数据查询，一般不会修改操作
- 随**时间变化**：不可更新是指数据仓库的**用户**进行分析处理是**不进行数据更新操作**的，但不代表数据仓库的**整个生存周期中数据集合**是不变的

### **数据湖**:

企业希望把**所有数据(结构化与非结构化)**都完整保存下来，进行有效管理与集中治理，挖掘和探索数据价值。

数据湖是一个集中存储各类**结构化和非结构化**数据的大型数据仓库，它可以存储来自**多个数据源、多种数据类型**的**原始数据**，数据**无需经过结构化处理**，就可以进行存取、处理、分析和传输。

对于数据仓库与数据湖的不同之处，可以类比为仓库和湖泊的区别：仓库存储着来自特定来源的货物；而湖泊的水来自河流、溪流和其他来源，**并且是原始数据**。
