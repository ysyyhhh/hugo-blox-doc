# Redis应用

## Redis分布式应用

### 分布式锁

分布式锁实现：

原始方式：setnx key true（死锁）/set key true ex 30 nx（锁误删）-> 锁重入问题。

Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：

- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

三个条件:
- 枷锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式, 需要使用SET + NX
- 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放, 加上 EX/PX
  - EX: 秒
  - PX: 毫秒
- 需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作, 使用uuid等分布式唯一ID

命令格式
```
set lock_key unique_id NX PX 30000
```
- lock_key: 锁的key
- unique_id: 客户端唯一ID
- NX: key不存在时才设置成功
- PX 30000: 设置过期时间为30秒

解锁一般要使用 Lua 脚本来保证原子性，因为 Redis 的删除操作不是原子的，可能会导致误删。

```lua
// 先比较是否是自己的锁，再删除
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```


Redis分布式锁的优点:
- **性能高**：Redis 是单线程的，所以性能非常高，可以支持高并发的请求。
- 实现简单：使用 Redis 的 setnx 命令就可以实现分布式锁，非常简单。
- 避免单点故障: Redis 支持主从复制和集群，可以避免单点故障。

缺点:
- 超时时间设置: 过长影响性能.
  - 合理超时时间设置: 基于续约机制，每隔一段时间对锁进行续约，保证锁不会过期。
- 锁的不可靠性: 旧主节点宕机，新主节点上的锁丢失。
  - 可以使用 Redlock 算法解决这个问题，Redlock 算法是 Redis 官方提供的一种分布式锁算法，可以保证在大部分节点正常运行的情况下，分布式锁可以正常工作。


TODO: Redis 如何解决集群情况下分布式锁的可靠性？
### 分布式session登录


Redisson 框架实现方式：Redis + Lua 实现。



## Redis过期删除 和 内存淘汰策略

### Redis过期键的删除策略

Redis过期键的删除策略包括定期删除和惰性删除。

惰性删除：客户端访问一个key的时候，Redis会先检查它的过期时间，如果发现过期就立刻删除这个key。
缺点: 浪费内存


定期删除：Redis会将设置了过期时间的key放到一个独立的字典中，并对该字典进行每秒10次的过期扫描，

过期扫描不会遍历字典中所有的key，而是采用了一种简单的贪心策略。该策略的删除逻辑如下：

1. 从过期字典中随机选择20个key；
2. 删除这20个key中**已过期的key**；
3. 如果已过期key的比例超过25%(大于5个)，则**重复步骤1**。

为了保证定期删除不会出现**循环过度**，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms

缺点: 不好控制频率, 过快可能导致CPU占用过高


Redis1实际使用的是定期删除和惰性删除相结合的方式来删除过期键。


#### Redis持久化时对过期键的处理


**RDB 中对过期键的处理**

RDB 生成阶段: 会检查 key 是否过期，如果过期则不会将其写入 RDB 文件。

RDB 加载阶段: 根据服务器是主还是从
- 主服务器: 会在加载 RDB 文件时，跳过过期的 key
- 从服务器: 全部加载进去, 因为在进行主从复制时会清空,所以没什么影响.


**AOF 中对过期键的处理**

AOF 文件写入阶段: 不会主动删除过期键, 当key被删除时, 在AOF文件中追加一条DEL命令

AOF 文件重写阶段: 会对Redis中的过期键进行检查, 不会将过期键写入到新的AOF文件中


### Redis内存淘汰策略


运行内存达到了某个阀值，就会触发内存淘汰机制，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory

分为两类: 

不进行数据淘汰
- neo-eviction

进行数据淘汰的策略

在过期时间内进行淘汰
- volatile-lru：从设置了过期时间的 key 中挑选最近最少使用的 key 淘汰
- volatile-ttl：从设置了过期时间的 key 中挑选将要过期的 key 淘汰
- volatile-random：从设置了过期时间的 key 中随机挑选 key 淘汰
- volatile-lfu：从设置了过期时间的 key 中挑选最少使用的 key 淘汰

在所有数据范围进行淘汰

- allkeys-lru：从所有 key 中挑选最近最少使用的 key 淘汰
- allkeys-random：从所有 key 中随机挑选 key 淘汰
- allkeys-lfu：从所有 key 中挑选最少使用的 key 淘汰


lfu是Redis4.0之后新增的

#### LRU的实现

实现近似的LRU

在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间

会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。

优点:
- 不维护大链表，节省内存
- 不需要移动链表，提高效率

缺点:
- 缓存污染问题: 应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间



#### LFU的引入和实现

Least Frequently Used，最近最不常用

根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”

相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息

```c++
typedef struct redisObject {
    ...
      
    // 24 bits，用于记录对象的访问信息
    unsigned lru:24;  
    ...
} robj;
```

在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。

在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，用来记录 key 的访问时间戳；低 8bit 存储 logc(Logistic Counter)，用来记录 key 的访问频次。



### 如何设计Redis Key的过期时间？

1. 热点数据不设置过期时间，**使其达到“物理”上的永不过期**，可以避免缓存击穿问题；
2. 在设置过期时间时，可以**附加一个随机数**，避免大量的key同时过期，导致缓存雪崩。

## Redis 缓存设计

### 缓存雪崩、缓存穿透、缓存预热、缓存更新和缓存降级是什么？

#### 缓存穿透

客户端**查询根本不存在的数据，使得请求直达存储层**，导致其负载过大，甚至宕机。出现这种情况的原因，可能是业务层误将缓存和库中的数据删除了，也可能是有人**恶意攻击，专门访问库中不存在的数据**。

解决方案：

1. 缓存空对象：存储层未命中后，仍然将空值存入缓存层，客户端再次访问数据时，缓存层会直接返回空值。
2. 布隆过滤器：将数据存入布隆过滤器，访问缓存之前以过滤器拦截，若请求的数据不存在则直接返回空值。
3. 非法请求的限制：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。

#### 缓存击穿

**一份热点数据，它的访问量非常大**。在其**缓存失效**的瞬间，大量请求直达存储层，导致服务崩溃。

解决方案：

1. 永不过期：热点数据不设置过期时间，所以不会出现上述问题，这是“物理”上的永不过期。或者为每个数据设置逻辑过期时间，当发现该数据**逻辑过期时，使用单独的线程重建缓存**。
2. 加互斥锁：对数据的访问加互斥锁，当一个线程访问该数据时，其他线程只能等待。这个线程访问过后，缓存中的数据将被重建，届时其他线程就可以直接从缓存中取值。

#### 缓存雪崩

在**某一时刻**，缓存层无法继续提供服务，导致大量请求直达存储层，造成数据库宕机。可能是**缓存中有大量数据同时过期**，也可能是Redis**节点发生故障，导致大量请求无法得到处理**。

解决方案：

1. 避免数据同时过期：设置过期时间时，附加一个随机数，避免大量的key同时过期。
2. 启用降级和熔断措施：在发生雪崩时，若应用访问的不是核心数据，则直接返回预定义信息/空值/错误信息。或者在发生雪崩时，对于访问缓存接口的请求，客户端并不会把请求发给Redis，而是直接返回。
3. 构建高可用的Redis服务：采用哨兵或集群模式，部署多个Redis实例，个别节点宕机，依然可以保持服务的整体可用。

### 动态缓存热点数据策略设计

通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据

只缓存用户经常访问的 Top 1000 的商品。具体细节如下：

- 先通过缓存系统做一个**排序队列（比如存放 1000 个商品）**，系统会根据商品的访问时间，更新队列信息，越是**最近访问的商品排名越靠前**；
- 同时系统会**定期过滤掉队列中排名最后的 200 个商品**，然后再从数据库中**随机读取出 200 个商品加入队列中**；
- 这样当**请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息**，并返回。
- 在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。


### 缓存与数据库的双写一致性(缓存更新策略)

常见的缓存更新策略共有3种：

- Cache Aside（旁路缓存）策略；
  - 先更新数据库，再删除缓存。
  - Cache Aside 策略适合**读多写少的场景，不适合写多的场景**
- Read/Write Through（读穿 / 写穿）策略；
  - 先更新数据库，再更新缓存。
- Write Back（写回）策略；

实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，

#### 先更新数据库再删除缓存 (Cache Aside)

写策略的步骤：
- 先更新数据库中的数据，再删除缓存中的数据。

读策略的步骤：

- 如果读取的数据命中了缓存，则直接返回数据；
- 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。

不能先删除缓存再更新数据库的原因:
- 「读+写」并发时, 数据不一致.

即删除了缓存之后, 还没有更新数据库, 这时候另一个线程读取了缓存, 由于缓存被删除, 从数据库中读取了旧数据.

#### 先更新数据库再更新缓存 Read/Write Through（读穿 / 写穿）策略

当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：

- 如果缓存中数据已经存在，则**更新缓存中的数据**，并且**由缓存组件同步更新到数据库中**，然后缓存组件告知应用程序更新完成。
- 如果缓存中数据不存在，直接更新数据库，然后返回；

不常使用的原因:
- 原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都**不提供写入数据库和自动加载数据库中的数据的功能**。


#### 只更新缓存 Write Back（写回）策略

Write Back 策略特别适合写多的场景，因为发生写操作的时候， 只需要更新缓存，就立马返回了。

比如，写文件的时候，实际上是写入到文件系统的缓存就返回了，并不会写磁盘。

但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险，

#### 保证 先更新数据库再删除缓存 操作成功

如果 在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值，而数据库是最新值。

采用异步操作缓存

**重试机制**

引入消息队列，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

- 如果**应用删除缓存失败，可以从消息队列中重新读取数据**，然后再次删除缓存，这个就是重试机制。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
- 如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。

**订阅 MySQL binlog，再操作缓存**

阿里的Canal 中间件就是这个策略

通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除

Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。

#### 延迟双删

针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「延迟双删」

```
#删除缓存
redis.delKey(X)
#更新数据库
db.update(X)
#睡眠
Thread.sleep(N)
#再删除缓存
redis.delKey(X)
```
睡眠时间是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存


#### 双写一致性策略分析

四种同步策略：

想要保证缓存与数据库的双写一致，一共有4种方式，即4种同步策略：

1. 先更新缓存，再更新数据库；
2. 先更新数据库，再更新缓存；
3. 先删除缓存，再更新数据库；
4. 先更新数据库，再删除缓存

从这4种同步策略中，我们需要作出比较的是：

1. 更新缓存与删除缓存哪种方式更合适？
2. 应该先操作数据库还是先操作缓存？

更新缓存还是删除缓存：

下面，我们来分析一下，应该采用更新缓存还是删除缓存的方式。

- 更新缓存

  优点：每次数据变化都及时更新缓存，所以查询时不容易出现未命中的情况。

  缺点：更新缓存的消耗比较大。如果数据需要经过复杂的计算再写入缓存，那么频繁的更新缓存，就会影响服务器的性能。如果是写入数据频繁的业务场景，那么可能频繁的更新缓存时，却没有业务读取该数据。

- 删除缓存

  优点：操作简单，无论更新操作是否复杂，都是将缓存中的数据直接删除。

  缺点：删除缓存后，下一次查询缓存会出现未命中，这时需要重新读取一次数据库。

从上面的比较来看，一般情况下，删除缓存是更优的方案。

先操作数据库还是缓存：

下面，我们再来分析一下，应该先操作数据库还是先操作缓存。

首先，我们将先删除缓存与先更新数据库，在出现失败时进行一个对比：

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645695077865/A8EAB406CDF2717DDC4C9AB91E37092E)

如上图，是先删除缓存再更新数据库，在出现失败时可能出现的问题：

1. 进程A删除缓存成功；
2. 进程A更新数据库失败；
3. 进程B从缓存中读取数据；
4. 由于缓存被删，进程B无法从缓存中得到数据，进而从数据库读取数据；
5. 进程B从数据库成功获取数据，然后将数据更新到了缓存。

最终，缓存和数据库的数据是一致的，但仍然是旧的数据。而我们的期望是二者数据一致，并且是新的数据。


总结:
- 「先更新数据库，再删除缓存」的方案虽然保证了数据库与缓存的数据一致性，但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响。
- **对缓存命中率有很高的要求**，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况。
  - 带来的问题: 写入顺序的不同造成数据的不一致
  - 解决方法: 
    - 更新缓存前加锁, 保证写入顺序的一致性
    - 在更新完缓存时，给缓存加上较短的过期时间

## Redis集群

Redis可以采用一主多从的方式实现集群，也可以采用哨兵模式实现集群。

Redis集群的原理： 将数据分散到多个节点上存储，通过主从复制和哨兵机制保证数据的可用性和一致性。

Redis集群最大节点个数是16384。


### 主从复制

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器

**从服务器一般是只读**，并接受主服务器同步过来写操作命令，然后执行这条命令。

主从服务器之间的命令复制是异步进行的

使用 replicaof（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系

```shell
# 服务器 B 执行这条命令
replicaof <服务器 A 的 IP 地址> <服务器 A 的 Redis 端口号>
```
服务器 B 就会变成服务器 A 的「从服务器」，然后与主服务器进行第一次同步。

第一次同步的过程可分为三个阶段：

- 第一阶段是建立链接、协商同步；
- 第二阶段是主服务器同步数据给从服务器；
- 第三阶段是主服务器发送新写操作命令给从服务器

命令传播:

完成第一次同步后，双方之间就会维护一个 基于TCP长连接的命令传播。

#### 分摊主服务器压力

第一次数据同步的过程中，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件. 如果从服务器多,会影响主服务器的性能。

**从服务器可以有自己的从服务器**，我们可以把拥有从服务器的从服务器当作经理角色，它不仅可以接收主服务器的同步数据，自己也可以同时作为主服务器的形式将数据同步给从服务器

主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器

在「从服务器」上执行下面这条命令，使其作为目标服务器的从服务器
```
replicaof <目标服务器的IP> 6379
```

#### 增量复制

2.8之前会全部重新同步

从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用增量复制的方式继续同步, 即之后只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器


![](img/Redis应用/增量复试流程.png)

主服务器怎么知道要将哪些增量数据发送给从服务器呢？


- repl_backlog_buffer，是一个「环形」缓冲区，用于主从服务器断连后，从中找到差异的数据；
- replication offset，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「写」到的位置，从服务器使用 slave_repl_offset 来记录自己「读」到的位置。

在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。

网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：

- 如果判断出**从服务器要读取的数据**还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用增量同步的方式；
- 相反，如果判断出**从服务器要读取的数据**已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用全量同步的方式。

为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，尽可能的大一些

修改方法, 配置文件中的字段:
`repl-backlog-size 1mb`


### 哨兵模式

解决的问题: 主从服务器出现故障宕机时，需要手动进行恢复。


作用: 
- 监控主从服务器的运行状态
- 提供主从节点故障转移功能


![](img/Redis应用/哨兵模式.png)


#### 监控

每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵

如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「主观下线」。这个「规定的时间」是配置项 down-after-milliseconds 参数设定的，单位是毫秒。


为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成**哨兵集群**（最少需要三台机器来部署哨兵集群），通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况

当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。当**超过半数的哨兵节点都认为主节点为「主观下线」**时，就会将主节点标记为「客观下线」。

#### 选主

从哨兵集群中选出一个哨兵节点作为领导者，这个领导者负责进行故障转移的操作

候选者: 判断主节点为「客观下线」的那个节点

选举过程:
- 候选者主动向哨兵集群发起选举请求
- 每个哨兵节点都会对候选者进行投票
  - 投给自己(只有候选者可以)
  - 投给其他哨兵
- 任何一个候选者同时满足
  - 半数以上赞成票
  - 票数大于等于配置文件的 `quorum` 参数

##### 哨兵节点至少要有三个

如果一个哨兵想要成功成为 Leader，必须获得 2 票，而不是 1 票

挂掉一个还能进行投票

挂掉两个就需要人为介入或增加哨兵节点

quorum 的值建议设置为哨兵个数的二分之一加 1，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且哨兵节点的数量应该是奇数。

#### 主从故障转移

1. 在已下线主节点（旧主节点）属下的**所有「从节点」里面，挑选出一个从节点**，并将其转换为主节点。
2. 让已下线主节点属下的**所有「从节点」修改复制目标**，修改为复制「新主节点」；
3. 将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」**通知给客户端**；
4. 继续监视旧主节点，**当这个旧主节点重新上线时，将它设置为新主节点的从节点**


#### 哨兵集群的组成

哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的。

- 互相感知: 在主从集群中，主节点上有一个名为__sentinel__:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。
- 建立连接: 哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息, 从而可以建立连接

### 切片集群模式

当 Redis 缓存数据量大到一台服务器无法缓存, 需要切片集群

Redis 3.0 之后的版本支持切片集群模式，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽

- 根据键值对的 key，按照 CRC16 算法 (opens new window)计算一个 16 bit 的值。
- 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

哈希槽映射到Redis节点方式:
- 平均分配: 将 16384 个哈希槽均匀分配到每个 Redis 节点上
- 手动分配: 指定每个 Redis 节点负责的哈希槽范围
  - 在手动分配哈希槽时，**需要把 16384 个槽都分配完**，否则 Redis 集群无法正常工作。

#### 为什么不使用一致性哈希


[得物面试：为啥Redis用哈希槽，不用一致性哈希？](https://mp.weixin.qq.com/s/Q68UN34-BqxyQFtkJL98lg)



### 集群脑裂问题

Redis架构一般是一主多从.

- 如果主节点与从节点断开
- 但不与客户端断开

从节点中会选举出一个新主节点.

但此时客户端还在与旧主节点通信, 会集群出现两个主节点

脑裂问题:
- 当旧主节点和新主节点之间网络恢复后, 会出现数据不一致问题
leader哨兵会把旧主节点设置为从节点(A), A向新主节点请求同步数据.
- 第一次是全量同步, 旧主节点A会清空本地数据. 那么之前**客户端写入A的数据就会丢失**

解决方案:

当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

对应的参数:
- min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。
- min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。

这样在选举完后, 不会出现丢失问题, 因为旧主节点不会再接收写请求.


## Redis实战

### Redis实现延迟队列

使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间

使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 **zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务**即可。

### Redis的大Key处理



### Redis是否支持事务

Redis 支持事务，但是 Redis 的事务和数据库的事务是不同的。

开启事务, 使用 MULTI 命令，然后执行多个命令，最后使用 EXEC 命令来执行事务中的所有命令。




Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空.

```
#读取 count 的值4
127.0.0.1:6379> GET count
"1"
#开启事务
127.0.0.1:6379> MULTI 
OK
#发送事务的第一个操作，对count减1
127.0.0.1:6379> DECR count
QUEUED
#执行DISCARD命令，主动放弃事务
127.0.0.1:6379> DISCARD
OK
#再次读取a:stock的值，值没有被修改
127.0.0.1:6379> GET count
"1"
```

因此 Redis 并**不一定保证原子性**

Redis 的事务是通过 MULTI 和 EXEC 命令来实现的，它的事务是一个单独的操作，不会被其他客户端的命令打断。

Redis的事务是不支持回滚的

作者不支持事务回滚的原因有以下两个：

- **Redis 事务的执行时，错误通常都是编程错误造成的**，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能；
- 不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。

这里不支持事务回滚，指的是不支持事务运行时错误的事务回滚。



## 其他

23、Redis集群会导致整个集群不可用的情况有哪些？

Redis集群会导致整个集群不可用的情况包括节点故障、网络分区等。

24、Redis支持的Java客户端有哪些？

Redis支持的Java客户端包括Jedis、Lettuce、Redisson等，官方推荐使用Lettuce。

25、Jedis与Redisson对比的优缺点有哪些？

Jedis与Redisson对比的优缺点包括性能、功能、易用性等方面。





