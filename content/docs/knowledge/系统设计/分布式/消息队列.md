# 消息队列

## MQ的作用

### 解耦

场景：A订单系统，B库存系统，A下单后需要减少库存。
传统做法：A调用B的接口。
问题：
- B无法访问时，A的操作将失败
- A需要知道B的存在，如果B接口需要修改时，A也需要修改

消息队列：A只与消息队列交互，不直接与B交互
- B的系统崩溃和更改对A没有关系

### 异步

场景：A下单后，需要B发送短信和C发送邮件

传统做法：
- 串行：A下单后，调用B发送短信，B发送成功后调用C发送邮件
- 并行：A下单后，调用B发送短信，同时调用C发送邮件

问题：
- A的等待时间过长，且BC不是必须的业务逻辑

消息队列
- A下单后，发送消息到消息队列，B和C监听消息队列，收到消息后发送短信和邮件
- 这样A不需要等待BC的操作，提高了响应速度

### 流量削峰

场景：秒杀活动，瞬间大量请求

传统做法：
- 直接请求，导致系统崩溃
- 限流，丢弃部分请求

消息队列
- 请求先发送到消息队列，然后慢慢处理
- 如果消息队列处理不过来，可以通过增加消费者来处理
- 如果消息队列过长才会丢弃部分请求

### 消息通信

点对点通信：客户端A和客户端B都使用同一个队列，A发送消息到队列，B从队列中取出消息

聊天室通信：客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。

### 日志处理

使用消息队列完成日志处理
- 日志采集客户端，负责日志数据采集，定时写受写入Kafka队列
- Kafka消息队列，负责日志数据的接收，存储和转发
- 日志处理应用：订阅并消费kafka队列中的日志数据

## MQ的问题

保证高可用

重复消费消息问题

消息丢失问题

消费的顺序性问题

分布式事务问题

消息堆积问题

## 三个消息队列的区别

RabbitMQ、Kafka和RocketMQ是三种不同特点的开源消息队列系统，各自适用于不同的场景。总结如下：

- RabbitMQ适用于需要可靠消息传递和灵活消息模型的场景，具有丰富的插件和社区支持。
- Kafka适用于高吞吐量、低延迟的实时数据处理和事件驱动架构场景，具有良好的可伸缩性和持久性。
- RocketMQ适用于高性能、高可用性的消息传递场景，具有丰富的消息过滤和分布式事务特性。

## Kafka

是一个分布式流式处理平台

RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。

## RocketMQ

使用主题模型

![](img/消息队列/RocketMQ的主题模型.png)

主题中会存在多个队列

多个队列可以提高并发能力

每个主题中都有多个队列(分布在不同的 Broker中，如果是集群的话，Broker又分布在不同的服务器中)，集群消费模式下，一个消费者集群多台机器共同消费一个 topic 的多个队列，一个队列只会被一个消费者消费。

一般来讲要控制 消费者组中的消费者个数和主题中队列个数相同 。


每个消费组在每个队列上维护一个消费位置
每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了。



### RocketMQ结构

Broker：主要负责消息的存储、投递和查询以及服务高可用保证。
- 说白了就是消息队列服务器嘛，生产者生产消息到 Broker ，消费者从 Broker 拉取消息并消费。
- 一个 Topic 分布在多个 Broker上，一个 Broker 可以配置多个 Topic ，它们是多对多的关系。

NameServer：注册中心
- 主要提供两个功能：Broker 管理 和 路由信息管理 。
- 说白了就是 Broker 会将自己的信息注册到 NameServer 中，此时 NameServer 就存放了很多 Broker 的信息(Broker 的路由表)，消费者和生产者就从 NameServer 中获取路由表然后照着路由表的信息和对应的 Broker 进行通信(生产者和消费者定期会向 NameServer 去查询相关的 Broker 的信息)。


Producer：消息发布的角色，支持分布式集群方式部署。说白了就是生产者。

Consumer：消息消费的角色，支持分布式集群方式部署。支持以 push 推，pull 拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。说白了就是消费者。

### 消息类型

普通消息

定时消息

顺序消息
Apache RocketMQ 保证相同消息组的消息存储在同一个队列中，如果不同业务场景的消息都集中在少量或一个消息组中，则这些消息存储压力都会集中到服务端的少量队列或一个队列中。

事务消息

### 解决顺序问题

普通顺序模式 ，我们从上面学习知道了在 Producer 生产消息的时候会进行轮询(取决你的负载均衡策略)来向同一主题的不同消息队列发送消息。

如果有几个消息分别是同一个订单的创建、支付、发货，在轮询的策略下这 **三个消息会被发送到不同队列** ，因为在不同的队列此时就无法使用 RocketMQ 带来的队列有序特性来保证消息有序性了。

解决方法: 将同一语义下的消息放入同一个队列(比如这里是同一个订单)

队列选择算法:
- 轮询
- 最小投递延迟, 选择队列时优先选择消息延时小的队列，导致消息分布不均匀,按照如下设置即可

### 分布式事务

RocketMQ 提供了事务消息 + 事务反查的机制来保证分布式事务的最终一致性。

![](img/消息队列/RocketMQ实现分布式事务.png)

half消息: 在事务提交之前, 对于消费者来说是不可见的消息


> 如何做到写入消息但是对用户不可见呢？RocketMQ 事务消息的做法是：如果消息是 half 消息，将备份原消息的主题与消息消费队列，然后 改变主题 为 RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费 half 类型的消息
> RocketMQ 会开启一个定时任务，从 Topic 为 RMQ_SYS_TRANS_HALF_TOPIC 中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。


### 消费堆积问题

产生消息堆积的原因——生产者生产太快或者消费者消费太慢

当流量到峰值的时候是因为生产者生产太快
- 可以使用一些 限流降级 的方法
- 可以增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。

如果消费者消费过慢的话
- 先检查 是否是消费者出现了大量的消费错误
- 打印一下日志查看是否是哪一个线程卡死，出现了锁资源不释放等等的问题。


#### RocketMQ的回溯消息

回溯消费是指 Consumer 已经消费成功的消息，由于业务上需求需要重新消费，在RocketMQ 中， Broker 在向Consumer 投递成功消息后，消息仍然需要保留 。并且重新消费一般是按照时间维度，例如由于 Consumer 系统故障，恢复后需要重新消费 1 小时前的数据，那么 Broker 要提供一种机制，可以按照时间维度来回退消费进度。RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒。

### RocketMQ的刷盘时机

在同步刷盘中需要等待一个刷盘成功的 ACK ，同步刷盘对 MQ 消息可靠性来说是一种不错的保障，但是 性能上会有较大影响 ，一般地适用于金融等特定业务场景。

异步刷盘往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行， 降低了读写延迟 ，提高了 MQ 的性能和吞吐量，一般适用于如发验证码等对于消息保证要求不太高的业务场景。一般地，异步刷盘只有在 Broker 意外宕机的时候会丢失部分数据


同步复制和异步复制

- 同步复制：也叫 “同步双写”，也就是说，只有消息同步双写到主从节点上时才返回写入成功 。
- 异步复制：消息写入主节点之后就直接返回写入成功 。
  - 异步复制**不会**像异步刷盘那样影响消息的可靠性
  - 但无法保证 严格顺序

### RocketMQ的存储机制

RocketMQ 消息存储架构中的三大角色——CommitLog、ConsumeQueue 和 IndexFile

CommitLog：消息主体以及元数据的存储主体，存储 Producer 端写入的消息主体内容

ConsumeQueue：消息消费队列，存储消息的消费队列，存储 Consumer 端消费的消息

IndexFile：消息索引文件，存储消息的索引信息，用于快速检索消息

![](img/消息队列/RocketMQ的存储结构.png)


左边的生产者发送消息会指定 Topic、QueueId 和具体消息内容，而在 Broker 中管你是哪门子消息，他直接 **全部顺序存储到了 CommitLog**。

根据生产者指定的 Topic 和 QueueId 将这条消息本身在 CommitLog 的偏移(offset)，消息本身大小，和 tag 的 hash 值存入对应的 ConsumeQueue 索引文件中

消费者拉取消息进行消费的时候只需要根据 ConsumeOffset 获取下一个未被消费的消息就行了。


## RabbitMQ

AMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品、不同的开发语言等条件的限制。


### 底层原理

![](img/消息队列/RabbitMQ底层.png)

- Producer：消息生产者，负责生产消息，然后发送给 RabbitMQ 服务器.
- Exchange：消息交换机，接收生产者发送的消息，然后将消息发送给队列。
- Queue：消息队列，存储生产者发送的消息。
- Consumer：消息消费者，从队列中获取消息，进行消费。

Exchange(交换器) 有 4 种类型，不同的类型对应着不同的路由策略：direct(默认)，fanout, topic, 和 headers，

生产者将消息发给交换器的时候，一般会指定一个 RoutingKey(路由键)，用来**指定这个消息的路由规则**，当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中


多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（Round-Robin，即轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样避免消息被重复消费。RabbitMQ 不支持队列层面的广播消费,如果有广播消费的需求，需要在其上进行二次开发,这样会很麻烦，不建议这样做



### 死信队列


### 保证消费一致性

只有RocketMQ支持事务消息。

### 保证不重复消费（幂等性问题）？

想要保证不重复消费，其实还要结合业务来思考，这里给几个思路：

比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下。

比如你是写redis，那没问题了，反正每次都是set，天然幂等性。

比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据。

### 保证消息的顺序性？

RabbitMQ 的问题是由于不同的消息都发送到了同一个 queue 中，多个消费者都消费同一个 queue 的消息。

拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点；

或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

### 实现延迟队列

消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。

RabbitMQ本身没有延迟队列的实现

RabbitMQ实现延迟队列的两种方式：
- 死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）。
- 3.5.7 及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能。同时，插件依赖 Erlang/OPT 18.0 及以上。

### 推拉

推模式：

推模式是服务器端根据用户需要，由目的、按时将用户感兴趣的信息主动发送到用户的客户端。

优点：

对用户要求低，方便用户获取需要的信息；

及时性好，服务器端及时地向客户端推送更新动态信息，吞吐量大。

缺点：

不能确保发送成功，推模式采用广播方式，只有服务器端和客户端在同一个频道上，推模式才有效，用户才能接收到信息；

没有信息状态跟踪，推模式采用开环控制技术，一个信息推送后的状态，比如客户端是否接收等，无从得知；

针对性较差。推送的信息可能并不能满足客户端的个性化需求。

拉模式：

拉模式是客户端主动从服务器端获取信息。

优点：

针对性强，能满足客户端的个性化需求；

信息传输量较小，网络中传输的只是客户端的请求和服务器端对该请求的响应；

服务器端的任务轻。服务器端只是被动接收查询，对客户端的查询请求做出响应。

缺点：

实时性较差，针对于服务器端实时更新的信息，客户端难以获取实时信息；

对于客户端用户的要求较高，需要对服务器端具有一定的了解。

### 消息队列如何保证消息不丢

丢数据一般分为两种，一种是mq把消息丢了，一种就是消费时将消息丢了。下面从rabbitmq和kafka分别说一下，丢失数据的场景。

RabbitMQ丢失消息分为如下几种情况：

#### 生产者丢消息

- 生产者将数据发送到RabbitMQ的时候，可能在传输过程中因为网络等问题而将数据弄丢了。

- 可以选择使用RabbitMQ提供是**事务功能**，就是生产者在发送数据之前开启事务，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会受到异常报错，这时就可以回滚事务，然后尝试重新发送。如果收到了消息，那么就可以提交事务。这种方式有明显的缺点，即RabbitMQ事务开启后，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。

- 可以开启**confirm模式**。在生产者那里设置开启了confirm模式之后，每次写的消息都会分配一个唯一的id，然后如何写入了RabbitMQ之中，RabbitMQ会给你回传一个ack消息，告诉你这个消息发送OK了。如果RabbitMQ**没能处理这个消息，会回调你一个nack接口**，告诉你这个消息失败了，你可以进行重试。而且你可以结合这个机制知道自己在内存里维护每个消息的id，如果超过一定时间还没接收到这个消息的回调，那么你可以进行重发。

事务机制是同步的，你提交了一个事物之后会阻塞住，但是confirm机制是异步的，发送消息之后可以接着发送下一个消息，然后RabbitMQ会回调告知成功与否。 一般在生产者这块避免丢失，都是用confirm机制。

#### RabbitMQ自己丢消息

- 如果没有开启RabbitMQ的持久化，那么RabbitMQ一旦重启数据就丢了。
- 所以必须**开启持久化将消息持久化到磁盘**，这样就算RabbitMQ挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢失。除非极其罕见的情况，RabbitMQ还没来得及持久化自己就挂了，这样可能导致一部分数据丢失。

设置消息持久化到磁盘，设置持久化有两个步骤：

- 创建queue的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化queue的元数据，但是不会持久化queue里面的数据。

- 发送消息的时候讲消息的deliveryMode设置为2，这样消息就会被设为持久化方式，此时RabbitMQ就会将消息持久化到磁盘上。 必须要同时开启这两个才可以。

- 而且持久化可以跟生产的confirm机制配合起来，只有消息持久化到了磁盘之后，才会通知生产者ack，这样就算是在持久化之前RabbitMQ挂了，数据丢了，生产者收不到ack回调也会进行消息重发。


#### 消费端丢消息

主要是因为消费者消费时，刚消费到还没有处理，结果消费者就挂了，这样你重启之后，RabbitMQ就认为你已经消费过了，然后就丢了数据。

**使用RabbitMQ提供的ack机制**，首先关闭RabbitMQ的自动ack，然后每次在确保处理完这个消息之后，在代码里手动调用ack。这样就可以避免消息还没有处理完就ack。
