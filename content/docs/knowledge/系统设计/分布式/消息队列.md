# 消息队列

## MQ的作用

### 解耦

场景：A订单系统，B库存系统，A下单后需要减少库存。
传统做法：A调用B的接口。
问题：
- B无法访问时，A的操作将失败
- A需要知道B的存在，如果B接口需要修改时，A也需要修改

消息队列：A只与消息队列交互，不直接与B交互
- B的系统崩溃和更改对A没有关系

### 异步

场景：A下单后，需要B发送短信和C发送邮件

传统做法：
- 串行：A下单后，调用B发送短信，B发送成功后调用C发送邮件
- 并行：A下单后，调用B发送短信，同时调用C发送邮件

问题：
- A的等待时间过长，且BC不是必须的业务逻辑

消息队列
- A下单后，发送消息到消息队列，B和C监听消息队列，收到消息后发送短信和邮件
- 这样A不需要等待BC的操作，提高了响应速度

### 流量削峰

场景：秒杀活动，瞬间大量请求

传统做法：
- 直接请求，导致系统崩溃
- 限流，丢弃部分请求

消息队列
- 请求先发送到消息队列，然后慢慢处理
- 如果消息队列处理不过来，可以通过增加消费者来处理
- 如果消息队列过长才会丢弃部分请求

### 消息通信

点对点通信：客户端A和客户端B都使用同一个队列，A发送消息到队列，B从队列中取出消息

聊天室通信：客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。

### 日志处理

使用消息队列完成日志处理
- 日志采集客户端，负责日志数据采集，定时写受写入Kafka队列
- Kafka消息队列，负责日志数据的接收，存储和转发
- 日志处理应用：订阅并消费kafka队列中的日志数据

## RabbitMQ

AMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品、不同的开发语言等条件的限制。


### 底层原理

### 死信队列


### RabbitMQ如何保证消费一致性


### 消息队列如何保证不重复消费（幂等性问题）？

不丢

想要保证不重复消费，其实还要结合业务来思考，这里给几个思路：



比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下。

比如你是写redis，那没问题了，反正每次都是set，天然幂等性。

比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据。

### 如何保证 RabbitMQ 消息的顺序性？

RabbitMQ 的问题是由于不同的消息都发送到了同一个 queue 中，多个消费者都消费同一个 queue 的消息。


拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点；

或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

### 推拉

推模式：

推模式是服务器端根据用户需要，由目的、按时将用户感兴趣的信息主动发送到用户的客户端。

优点：

对用户要求低，方便用户获取需要的信息；

及时性好，服务器端及时地向客户端推送更新动态信息，吞吐量大。

缺点：

不能确保发送成功，推模式采用广播方式，只有服务器端和客户端在同一个频道上，推模式才有效，用户才能接收到信息；

没有信息状态跟踪，推模式采用开环控制技术，一个信息推送后的状态，比如客户端是否接收等，无从得知；

针对性较差。推送的信息可能并不能满足客户端的个性化需求。

拉模式：

拉模式是客户端主动从服务器端获取信息。

优点：

针对性强，能满足客户端的个性化需求；

信息传输量较小，网络中传输的只是客户端的请求和服务器端对该请求的响应；

服务器端的任务轻。服务器端只是被动接收查询，对客户端的查询请求做出响应。

缺点：

实时性较差，针对于服务器端实时更新的信息，客户端难以获取实时信息；

对于客户端用户的要求较高，需要对服务器端具有一定的了解。

### 消息队列如何保证消息不丢
丢数据一般分为两种，一种是mq把消息丢了，一种就是消费时将消息丢了。下面从rabbitmq和kafka分别说一下，丢失数据的场景。

RabbitMQ丢失消息分为如下几种情况：

生产者丢消息：

- 生产者将数据发送到RabbitMQ的时候，可能在传输过程中因为网络等问题而将数据弄丢了。

- 可以选择使用RabbitMQ提供是**事务功能**，就是生产者在发送数据之前开启事务，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会受到异常报错，这时就可以回滚事务，然后尝试重新发送。如果收到了消息，那么就可以提交事务。这种方式有明显的缺点，即RabbitMQ事务开启后，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。
- 可以开启**confirm模式**。在生产者那里设置开启了confirm模式之后，每次写的消息都会分配一个唯一的id，然后如何写入了RabbitMQ之中，RabbitMQ会给你回传一个ack消息，告诉你这个消息发送OK了。如果RabbitMQ没能处理这个消息，会回调你一个nack接口，告诉你这个消息失败了，你可以进行重试。而且你可以结合这个机制知道自己在内存里维护每个消息的id，如果超过一定时间还没接收到这个消息的回调，那么你可以进行重发。

- 事务机制是同步的，你提交了一个事物之后会阻塞住，但是confirm机制是异步的，发送消息之后可以接着发送下一个消息，然后RabbitMQ会回调告知成功与否。 一般在生产者这块避免丢失，都是用confirm机制。

RabbitMQ自己丢消息：

- 如果没有开启RabbitMQ的持久化，那么RabbitMQ一旦重启数据就丢了。所以必须开启持久化将消息持久化到磁盘，这样就算RabbitMQ挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢失。除非极其罕见的情况，RabbitMQ还没来得及持久化自己就挂了，这样可能导致一部分数据丢失。

设置消息持久化到磁盘，设置持久化有两个步骤：

创建queue的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化queue的元数据，但是不会持久化queue里面的数据。

发送消息的时候讲消息的deliveryMode设置为2，这样消息就会被设为持久化方式，此时RabbitMQ就会将消息持久化到磁盘上。 必须要同时开启这两个才可以。

而且持久化可以跟生产的confirm机制配合起来，只有消息持久化到了磁盘之后，才会通知生产者ack，这样就算是在持久化之前RabbitMQ挂了，数据丢了，生产者收不到ack回调也会进行消息重发。


消费端丢消息：

主要是因为消费者消费时，刚消费到还没有处理，结果消费者就挂了，这样你重启之后，RabbitMQ就认为你已经消费过了，然后就丢了数据。

使用RabbitMQ提供的ack机制，首先关闭RabbitMQ的自动ack，然后每次在确保处理完这个消息之后，在代码里手动调用ack。这样就可以避免消息还没有处理完就ack。
